#################################################
# kafka 相关配置
#################################################
kafka.brokers=zorkdata-95:9092
kafka.group.id=log2es
# kafka topic,如果是多个 topic 使用 “,” 进行分隔
logs.topics=test

# kakfa 消费数据的模式: none,earliest,latest 字段含义与 kafka 的配置相同,默认是 latest
kafka.consumer.model=earliest


#################################################
# 任务相关配置
#################################################
stream.parallelism=5
stream.checkpoint.interval=60000
stream.checkpoint.enable=false

# checkpoint 类型: memory,fs,rocksdb (生产环境建议使用 rocksdb)
stream.checkpoint.type=rocksdb
stream.checkpoint.dir=hdfs://zorkdata-112:8020/flink/checkpoints
#设置 checkpoint 最小间隔 默认是500 ms
min.pause.between.checkpoints=500
# 设置 checkpoint 必须在设定时间内完成，否则会被丢弃,单位 ms,默认一分钟
checkpoint.timeout=60000

# 设置 checkpoint 的并发度,默认为1
max.concurrent.checkpoints=1
# 任务数据源的名称
stream.source.name=kafka-source
# 任务输出名称
stream.sink.name=es-sink
# 任务名称
stream.job.name=log2es


#################################################
# elasticsearch 相关配置
#################################################
elasticsearch.url=192.168.1.95:9200,192.168.1.92:9200
elasticsearch.cluster.name=test-cluster
elasticsearch.indexTopo="TXJY=>flink_txjy"
elasticsearch.bulk.flush.max.actions=2000
elasticsearch.bulk.flush.max.size.mb=500
elasticsearch.bulk.flush.interval.ms=3000