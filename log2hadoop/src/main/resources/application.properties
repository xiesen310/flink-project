#################################################
# kafka 相关配置
#################################################
kafka.brokers=zorkdata-95:9092
kafka.group.id=log2dfs
# kafka topic,如果是多个 topic 使用 “,” 进行分隔
logs.topics=test

# kakfa 消费数据的模式: none,earliest,latest 字段含义与 kafka 的配置相同,默认是 latest
kafka.consumer.model=earliest

#################################################
# hadoop 相关配置
#################################################
# hadoop 地址
hdfs.url=hdfs://zorkdata-112:8020/tmp/test_hdfs

# 写入 hdfs 文件大小,单位字节,默认是 128M
hdfs.batch.size=1024

# 设置多长时间写一个文件，单位ms， 默认 10分钟
hdfs.batch.rollover.interval=1200000

# 写入hadoop 数据目录结构
partition.field.name=dimensions['appsystem'],logTypeName,timestamp


#################################################
# 任务相关配置
#################################################
stream.parallelism=5
stream.checkpoint.interval=60000
stream.checkpoint.enable=false

# checkpoint 类型: memory,fs,rocksdb (生产环境建议使用 rocksdb)
stream.checkpoint.type=rocksdb
stream.checkpoint.dir=hdfs://zorkdata-112:8020/flink/checkpoints
#设置 checkpoint 最小间隔 默认是500 ms
min.pause.between.checkpoints=500
# 设置 checkpoint 必须在设定时间内完成，否则会被丢弃,单位 ms,默认一分钟
checkpoint.timeout=60000

# 设置 checkpoint 的并发度,默认为1
max.concurrent.checkpoints=1